{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitting import fit_all_models_parallel, fit_model_sequentially\n",
    "from agents.agents_configs import all_models, get_models_for_fitting, toggle_model_inclusion\n",
    "\n",
    "# Example usage:\n",
    "# Get all currently included models\n",
    "# models_to_fit = get_models_for_fitting()\n",
    "\n",
    "# Get only RW models (exclude RLWM)\n",
    "# models_to_fit = get_models_for_fitting(include_names=['rw'], exclude_names=['rlwm'])\n",
    "\n",
    "# Get models with specific patterns\n",
    "# models_to_fit = get_models_for_fitting(include_names=['rw_noise'])\n",
    "\n",
    "# Turn off specific models\n",
    "# toggle_model_inclusion(['rw_noise_bias_pav_dynamic_collins_decay_both'], include=False)\n",
    "\n",
    "# For standard progression, do:\n",
    "# toggle_model_inclusion(['rw_noise_bias_pav_dynamic_collins_decay_both', 'rw_noise_bias_pav_dynamic_collins_decay_q'], include=False)\n",
    "# models_to_fit = get_models_for_fitting(include_names=['rw'], exclude_names=['rlwm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(cfgs):\n",
    "    print(\"Current models available:\")\n",
    "    print(\"________________________\")\n",
    "    for model in cfgs:\n",
    "        print(f\"  - {model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current models available:\n",
      "________________________\n",
      "  - rw\n",
      "  - rw_noise\n",
      "  - rw_noise_bias\n",
      "  - rw_noise_bias_pav_dynamic\n",
      "  - rw_noise_bias_asym_reward\n",
      "  - rw_noise_bias_pav_dynamic_asym_decay_both\n",
      "  - rw_bayesian_control\n",
      "  - rw_bayesian_control_counterfactual\n",
      "  - rw_bayesian_pav\n",
      "  - rw_bayesian_pav_counterfactual\n",
      "  - rw_omega_control\n",
      "  - rw_reward_rate_bias\n",
      "  - rw_context_decay\n",
      "  - rw_win_stay_boost\n"
     ]
    }
   ],
   "source": [
    "# PyBADS Fitting Pipeline\n",
    "\n",
    "# 1. Select models for fitting\n",
    "toggle_model_inclusion(['rw_noise_bias_pav_dynamic_collins_decay_both', \n",
    "                       'rw_noise_bias_pav_dynamic_collins_decay_q'], include=False)\n",
    "\n",
    "models_to_fit = get_models_for_fitting(include_names=['rw'], exclude_names=['rlwm'])\n",
    "\n",
    "print_models(models_to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Reward recoding successful: 10240 trials with rewards [np.int64(-1), np.int64(1)]\n",
      "  Reward distribution: +1=6813, -1=3427\n"
     ]
    }
   ],
   "source": [
    "# 2. Set up data and fitting parameters for PyBADS\n",
    "from agents.robot_dataset import RobotDataset\n",
    "data = RobotDataset()\n",
    "toolbox = \"pybads\"\n",
    "fit_with_slurm = True\n",
    "\n",
    "# PyBADS-specific options\n",
    "bads_options = {\n",
    "    'max_fun_evals': 1000,\n",
    "    'tol_mesh': 1e-8,\n",
    "    'tol_fun': 1e-6,\n",
    "    'tol_stall_iters': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Reward recoding successful: 10240 trials with rewards [np.int64(-1), np.int64(1)]\n",
      "  Reward distribution: +1=6813, -1=3427\n",
      "Submitting jobs for 6 models with 2 subjects each...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b64a1eb1d544dccb030c12264880ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting jobs:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PYBADS for optimization\n",
      "Using PYBADS for optimization\n",
      "Using PYBADS for optimization\n",
      "Using PYBADS for optimization\n",
      "Using PYBADS for optimization\n",
      "Using PYBADS for optimization\n",
      "Submitted 12 total jobs to SLURM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2899c27dae074164b912d802853f6d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting results:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing population statistics for each model...\n",
      "Using PYBADS for optimization\n",
      "✓ rw: 2/2 subjects successful\n",
      "Using PYBADS for optimization\n",
      "✓ rw_noise: 2/2 subjects successful\n",
      "Using PYBADS for optimization\n",
      "✓ rw_noise_bias: 2/2 subjects successful\n",
      "Using PYBADS for optimization\n",
      "✓ rw_noise_bias_pav_dynamic: 2/2 subjects successful\n",
      "Using PYBADS for optimization\n",
      "✓ rw_noise_bias_asym_reward: 2/2 subjects successful\n",
      "Using PYBADS for optimization\n",
      "✓ rw_noise_bias_pav_dynamic_asym_decay_both: 2/2 subjects successful\n",
      "\n",
      "All results saved to: model_fits/logs/parallel_fitting/20250626_153351/all_models_results.pkl\n",
      "Fitted 6 models successfully!\n"
     ]
    }
   ],
   "source": [
    "# 3a) Fit all selected models with PyBADS\n",
    "pybads_results = fit_all_models_parallel(\n",
    "        models_to_fit=models_to_fit,\n",
    "        data=data,\n",
    "        toolbox=\"pybads\",\n",
    "        fit_with_slurm=True,\n",
    "        n_starts = 1,\n",
    "        bads_options=None,\n",
    "        developmental_subjects=['sub-001', 'sub-020'],\n",
    "        vbmc_init_with_bads=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Reward recoding successful: 10240 trials with rewards [np.int64(-1), np.int64(1)]\n",
      "  Reward distribution: +1=6813, -1=3427\n",
      "Submitting jobs for 6 models with 2 subjects each...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5af414fa7044e78df43757edd5e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting jobs:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "Submitted 12 total jobs to SLURM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1e7503d38c4823a6fc9ea29ab79427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting results:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing population statistics for each model...\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw: 2/2 subjects successful\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw_noise: 2/2 subjects successful\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw_noise_bias: 2/2 subjects successful\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw_noise_bias_pav_dynamic: 2/2 subjects successful\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw_noise_bias_asym_reward: 2/2 subjects successful\n",
      "Using PYVBMC for optimization\n",
      "Will initialize VBMC with PyBADS\n",
      "✓ rw_noise_bias_pav_dynamic_asym_decay_both: 2/2 subjects successful\n",
      "\n",
      "All results saved to: model_fits/logs/parallel_fitting/20250626_153457/all_models_results.pkl\n",
      "Fitted 6 models successfully!\n",
      "✓ PyVBMC fitting completed with PyBADS initialization!\n"
     ]
    }
   ],
   "source": [
    "# 3b) Fit all selected models with PyVBMC (using PyBADS for initialization)\n",
    "\n",
    "# PyVBMC-specific options\n",
    "vbmc_options = {\n",
    "    'max_fun_evals': 500,      # Fewer evaluations than PyBADS since it's more efficient\n",
    "    'tol_con_loss': 0.01,      # Convergence tolerance\n",
    "    'fun_eval_start': 10,      # Function evaluations before starting GP\n",
    "    'k_warmup': 5,             # Warmup iterations\n",
    "    'max_iter': 100            # Maximum iterations\n",
    "}\n",
    "\n",
    "# PyBADS initialization options (for PyVBMC)\n",
    "vbmc_bads_init_options = {\n",
    "    'max_fun_evals': 100,      # Quick initialization with PyBADS\n",
    "    'tol_fun': 1e-3,           # Looser tolerance for initialization\n",
    "    'tol_mesh': 1e-5           # Mesh tolerance\n",
    "}\n",
    "\n",
    "# Fit with PyVBMC using PyBADS initialization\n",
    "pyvbmc_results = fit_all_models_parallel(\n",
    "        models_to_fit=models_to_fit,\n",
    "        data=data,\n",
    "        toolbox=\"pyvbmc\",              # Use PyVBMC\n",
    "        fit_with_slurm=True,\n",
    "        n_starts=1,                    # Fewer starts needed with VBMC\n",
    "        vbmc_options=vbmc_options,\n",
    "        vbmc_bads_init_options=vbmc_bads_init_options,\n",
    "        developmental_subjects=['sub-001', 'sub-020'],\n",
    "        vbmc_init_with_bads=True       # Enable PyBADS initialization\n",
    "    )\n",
    "\n",
    "print(\"✓ PyVBMC fitting completed with PyBADS initialization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pybads_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Evidence (PyVBMC only): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevidence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Run the comparison\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m compare_fitting_results(\u001b[43mpybads_results\u001b[49m, pyvbmc_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pybads_results' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Compare PyBADS vs PyVBMC Results\n",
    "\n",
    "def compare_fitting_results(pybads_results, pyvbmc_results):\n",
    "    \"\"\"Compare fitting results between PyBADS and PyVBMC\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"FITTING RESULTS COMPARISON: PyBADS vs PyVBMC\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name in pybads_results.keys():\n",
    "        if model_name in pyvbmc_results:\n",
    "            print(f\"\\nModel: {model_name}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # PyBADS results\n",
    "            bads_pop_stats = pybads_results[model_name]['population_statistics']\n",
    "            bads_n_successful = pybads_results[model_name]['n_successful']\n",
    "            bads_n_total = pybads_results[model_name]['n_subjects']\n",
    "            \n",
    "            # PyVBMC results  \n",
    "            vbmc_pop_stats = pyvbmc_results[model_name]['population_statistics']\n",
    "            vbmc_n_successful = pyvbmc_results[model_name]['n_successful']\n",
    "            vbmc_n_total = pyvbmc_results[model_name]['n_subjects']\n",
    "            \n",
    "            print(f\"Convergence rate:\")\n",
    "            print(f\"  PyBADS:  {bads_n_successful}/{bads_n_total} ({100*bads_n_successful/bads_n_total:.1f}%)\")\n",
    "            print(f\"  PyVBMC:  {vbmc_n_successful}/{vbmc_n_total} ({100*vbmc_n_successful/vbmc_n_total:.1f}%)\")\n",
    "            \n",
    "            # Compare parameter estimates\n",
    "            if 'parameters' in bads_pop_stats and 'parameters' in vbmc_pop_stats:\n",
    "                print(f\"Parameter estimates:\")\n",
    "                for param in bads_pop_stats['parameters'].keys():\n",
    "                    if param in vbmc_pop_stats['parameters']:\n",
    "                        bads_mean = bads_pop_stats['parameters'][param]['mean']\n",
    "                        vbmc_mean = vbmc_pop_stats['parameters'][param]['mean']\n",
    "                        print(f\"  {param:12s}: PyBADS={bads_mean:.3f}, PyVBMC={vbmc_mean:.3f}\")\n",
    "            \n",
    "            # Compare log-likelihood\n",
    "            if 'log_likelihood' in bads_pop_stats and 'log_likelihood' in vbmc_pop_stats:\n",
    "                bads_ll = bads_pop_stats['log_likelihood']['total']\n",
    "                vbmc_ll = vbmc_pop_stats['log_likelihood']['total']\n",
    "                print(f\"Total Log-Likelihood:\")\n",
    "                print(f\"  PyBADS:  {bads_ll:.1f}\")\n",
    "                print(f\"  PyVBMC:  {vbmc_ll:.1f}\")\n",
    "                print(f\"  Difference: {vbmc_ll - bads_ll:.1f}\")\n",
    "                \n",
    "            # Model evidence (only available for PyVBMC)\n",
    "            if 'model_evidence' in vbmc_pop_stats and vbmc_pop_stats['model_evidence']:\n",
    "                evidence = vbmc_pop_stats['model_evidence'].get('total', 'N/A')\n",
    "                print(f\"Model Evidence (PyVBMC only): {evidence}\")\n",
    "\n",
    "# Run the comparison\n",
    "compare_fitting_results(pybads_results, pyvbmc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Loading Functions ===\n",
      "Found 17 parallel fitting directories:\n",
      "  1. 20250626_153457 - ✓ Has results\n",
      "  2. 20250626_153351 - ✓ Has results\n",
      "  3. 20250626_134248 - ✓ Has results\n",
      "  4. 20250626_134219 - ✗ No results file\n",
      "  5. 20250626_134005 - ✓ Has results\n",
      "  6. 20250626_133944 - ✗ No results file\n",
      "  7. 20250626_122734 - ✓ Has results\n",
      "  8. 20250626_122106 - ✓ Has results\n",
      "  9. 20250626_111358 - ✓ Has results\n",
      "  10. 20250626_110206 - ✓ Has results\n",
      "  11. 20250626_110126 - ✗ No results file\n",
      "  12. 20250626_102621 - ✓ Has results\n",
      "  13. 20250626_102258 - ✗ No results file\n",
      "  14. 20250626_101640 - ✗ No results file\n",
      "  15. 20250626_101345 - ✗ No results file\n",
      "  16. 20250626_100821 - ✗ No results file\n",
      "  17. 20250626_100216 - ✓ Has results\n",
      "Loaded parallel fit results from: /mnt/z/3017083.01/behavioral_study/scripts/gonogo-simfit/model_fits/logs/parallel_fitting/20250626_153457/all_models_results.pkl (dill)\n",
      "Found 6 models fitted\n",
      "\n",
      "✓ Successfully loaded 6 models from: /mnt/z/3017083.01/behavioral_study/scripts/gonogo-simfit/model_fits/logs/parallel_fitting/20250626_153457/all_models_results.pkl\n",
      "Models found: ['rw', 'rw_noise', 'rw_noise_bias', 'rw_noise_bias_pav_dynamic', 'rw_noise_bias_asym_reward', 'rw_noise_bias_pav_dynamic_asym_decay_both']\n",
      "\n",
      "Structure check for 'rw':\n",
      "  - fit_toolbox: pyvbmc\n",
      "  - n_subjects: 2\n",
      "  - n_successful: 2\n",
      "  - has population_statistics: True\n",
      "  - has individual_results: True\n"
     ]
    }
   ],
   "source": [
    "# Test loading functions\n",
    "from fitting import find_latest_parallel_fit_results, list_all_parallel_fit_results\n",
    "\n",
    "# List all available results\n",
    "print(\"=== Testing Loading Functions ===\")\n",
    "all_results = list_all_parallel_fit_results()\n",
    "\n",
    "# Try to load the latest results\n",
    "latest_results, latest_path = find_latest_parallel_fit_results()\n",
    "\n",
    "if latest_results:\n",
    "    print(f\"\\n✓ Successfully loaded {len(latest_results)} models from: {latest_path}\")\n",
    "    print(\"Models found:\", list(latest_results.keys()))\n",
    "    \n",
    "    # Check structure of one model\n",
    "    first_model = list(latest_results.keys())[0]\n",
    "    model_data = latest_results[first_model]\n",
    "    print(f\"\\nStructure check for '{first_model}':\")\n",
    "    print(f\"  - fit_toolbox: {model_data.get('fit_toolbox', 'N/A')}\")\n",
    "    print(f\"  - n_subjects: {model_data.get('n_subjects', 'N/A')}\")\n",
    "    print(f\"  - n_successful: {model_data.get('n_successful', 'N/A')}\")\n",
    "    print(f\"  - has population_statistics: {'population_statistics' in model_data}\")\n",
    "    print(f\"  - has individual_results: {'individual_results' in model_data}\")\n",
    "else:\n",
    "    print(\"✗ Failed to load results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiRLfit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
